\relax 
\citation{Kell2020c}
\citation{Kell,Kell2020}
\citation{Kell2019a}
\citation{Hunt2016a}
\citation{Ye2020a}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}\protected@file@percent }
\newlabel{sec:introduction}{{I}{1}}
\citation{EsmaeiliAliabadi2017,Tellidou2007}
\citation{Wang2011}
\citation{Wang2011}
\citation{EsmaeiliAliabadi2017}
\citation{VijayaKumar2014}
\citation{Wang2011}
\citation{Bell2010}
\citation{Yang2020}
\@writefile{toc}{\contentsline {section}{\numberline {II}Literature Review}{2}\protected@file@percent }
\newlabel{sec:lit-review}{{II}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Game-theoretic approaches}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Simulation}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-C}}Reinforcement learning to model intelligence}{2}\protected@file@percent }
\citation{EsmaeiliAliabadi2017}
\citation{Bertrand2019}
\citation{Ye2020a}
\citation{Schaul2016}
\citation{Zhao2016}
\citation{Gay2007}
\citation{Sutton2015}
\@writefile{toc}{\contentsline {section}{\numberline {III}Methodology}{3}\protected@file@percent }
\newlabel{sec:material}{{III}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Reinforcement Learning background}{3}\protected@file@percent }
\newlabel{eq:action-value}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Q-Learning}{3}\protected@file@percent }
\newlabel{eq:bellman}{{2}{3}}
\citation{Gay2007}
\citation{Hunt2016a}
\citation{Silver2014}
\citation{Hunt2016a}
\citation{Hunt2016a}
\citation{Kell,Kell2020}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Deep Deterministic Gradient Policy}{4}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces DDPG Algorithm \cite  {Hunt2016a}\relax }}{4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:ddpg}{{1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-D}}Simulation}{4}\protected@file@percent }
\citation{Kell2020}
\citation{Kell}
\citation{Kell}
\citation{dukes_511}
\citation{gbnationalgridstatus_2019}
\citation{Pfenninger2016}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces System overview of ElecSim \cite  {Kell}.\relax }}{5}\protected@file@percent }
\newlabel{fig:model_details}{{1}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experimental Setup}{5}\protected@file@percent }
\newlabel{sec:methodology}{{IV}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-A}}Model Parametrization}{5}\protected@file@percent }
\citation{EsmaeiliAliabadi2017}
\citation{EsmaeiliAliabadi2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-B}}Reinforcement Learning Setup}{6}\protected@file@percent }
\newlabel{eq:observation_tuple}{{6}{6}}
\newlabel{eq:reward}{{7}{6}}
\newlabel{eq:p_avg}{{8}{6}}
\newlabel{eq:action-space-scen-1}{{9}{6}}
\newlabel{eq:action-space-scen-2}{{10}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Results}{6}\protected@file@percent }
\newlabel{sec:results}{{V}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Groups of GenCos that used bidding strategies, number of plants and total electricity generating capacity.\relax }}{7}\protected@file@percent }
\newlabel{table:genco_table}{{I}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Reward over time for different groups of GenCos, max bid = \textsterling $600$/MWh.\relax }}{7}\protected@file@percent }
\newlabel{fig:unbounded_timesteps}{{2}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Reward over time for different groups of GenCos, max bid = \textsterling $150$/MWh.\relax }}{7}\protected@file@percent }
\newlabel{fig:bounded_timesteps}{{3}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Capacity of agents using RL vs. aver